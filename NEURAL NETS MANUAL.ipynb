{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_forward_test_case():\n",
    "    np.random.seed(1)\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    W = np.array([[ 0.74505627, 1.97611078, -1.24412333]])\n",
    "    b = np.array([[1]])\n",
    "    \"\"\"\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    \n",
    "    return A, W, b\n",
    "\n",
    "def linear_activation_forward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    W = np.array([[ 0.74505627, 1.97611078, -1.24412333]])\n",
    "    b = 5\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    A_prev = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    return A_prev, W, b\n",
    "\n",
    "def L_model_forward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    parameters = {'W1': np.array([[ 1.62434536, -0.61175641, -0.52817175],\n",
    "        [-1.07296862,  0.86540763, -2.3015387 ]]),\n",
    " 'W2': np.array([[ 1.74481176, -0.7612069 ]]),\n",
    " 'b1': np.array([[ 0.],\n",
    "        [ 0.]]),\n",
    " 'b2': np.array([[ 0.]])}\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    X = np.random.randn(4,2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return X, parameters\n",
    "\n",
    "def compute_cost_test_case():\n",
    "    Y = np.asarray([[1, 1, 1]])\n",
    "    aL = np.array([[.8,.9,0.4]])\n",
    "    \n",
    "    return Y, aL\n",
    "\n",
    "def linear_backward_test_case():\n",
    "    \"\"\"\n",
    "    z, linear_cache = (np.array([[-0.8019545 ,  3.85763489]]), (np.array([[-1.02387576,  1.12397796],\n",
    "       [-1.62328545,  0.64667545],\n",
    "       [-1.74314104, -0.59664964]]), np.array([[ 0.74505627,  1.97611078, -1.24412333]]), np.array([[1]]))\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    dZ = np.random.randn(1,2)\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    linear_cache = (A, W, b)\n",
    "    return dZ, linear_cache\n",
    "\n",
    "def linear_activation_backward_test_case():\n",
    "    \"\"\"\n",
    "    aL, linear_activation_cache = (np.array([[ 3.1980455 ,  7.85763489]]), ((np.array([[-1.02387576,  1.12397796], [-1.62328545,  0.64667545], [-1.74314104, -0.59664964]]), np.array([[ 0.74505627,  1.97611078, -1.24412333]]), 5), np.array([[ 3.1980455 ,  7.85763489]])))\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    dA = np.random.randn(1,2)\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    Z = np.random.randn(1,2)\n",
    "    linear_cache = (A, W, b)\n",
    "    activation_cache = Z\n",
    "    linear_activation_cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return dA, linear_activation_cache\n",
    "\n",
    "def L_model_backward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.random.rand(3,2)\n",
    "    Y = np.array([[1, 1]])\n",
    "    parameters = {'W1': np.array([[ 1.78862847,  0.43650985,  0.09649747]]), 'b1': np.array([[ 0.]])}\n",
    "    aL, caches = (np.array([[ 0.60298372,  0.87182628]]), [((np.array([[ 0.20445225,  0.87811744],\n",
    "           [ 0.02738759,  0.67046751],\n",
    "           [ 0.4173048 ,  0.55868983]]),\n",
    "    np.array([[ 1.78862847,  0.43650985,  0.09649747]]),\n",
    "    np.array([[ 0.]])),\n",
    "   np.array([[ 0.41791293,  1.91720367]]))])\n",
    "   \"\"\"\n",
    "    np.random.seed(3)\n",
    "    AL = np.random.randn(1, 2)\n",
    "    Y = np.array([[1, 0]])\n",
    "\n",
    "    A1 = np.random.randn(4,2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    Z1 = np.random.randn(3,2)\n",
    "    linear_cache_activation_1 = ((A1, W1, b1), Z1)\n",
    "\n",
    "    A2 = np.random.randn(3,2)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    Z2 = np.random.randn(1,2)\n",
    "    linear_cache_activation_2 = ((A2, W2, b2), Z2)\n",
    "\n",
    "    caches = (linear_cache_activation_1, linear_cache_activation_2)\n",
    "\n",
    "    return AL, Y, caches\n",
    "\n",
    "def update_parameters_test_case():\n",
    "    \"\"\"\n",
    "    parameters = {'W1': np.array([[ 1.78862847,  0.43650985,  0.09649747],\n",
    "        [-1.8634927 , -0.2773882 , -0.35475898],\n",
    "        [-0.08274148, -0.62700068, -0.04381817],\n",
    "        [-0.47721803, -1.31386475,  0.88462238]]),\n",
    " 'W2': np.array([[ 0.88131804,  1.70957306,  0.05003364, -0.40467741],\n",
    "        [-0.54535995, -1.54647732,  0.98236743, -1.10106763],\n",
    "        [-1.18504653, -0.2056499 ,  1.48614836,  0.23671627]]),\n",
    " 'W3': np.array([[-1.02378514, -0.7129932 ,  0.62524497],\n",
    "        [-0.16051336, -0.76883635, -0.23003072]]),\n",
    " 'b1': np.array([[ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.]]),\n",
    " 'b2': np.array([[ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.]]),\n",
    " 'b3': np.array([[ 0.],\n",
    "        [ 0.]])}\n",
    "    grads = {'dW1': np.array([[ 0.63070583,  0.66482653,  0.18308507],\n",
    "        [ 0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ]]),\n",
    " 'dW2': np.array([[ 1.62934255,  0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ,  0.        ]]),\n",
    " 'dW3': np.array([[-1.40260776,  0.        ,  0.        ]]),\n",
    " 'da1': np.array([[ 0.70760786,  0.65063504],\n",
    "        [ 0.17268975,  0.15878569],\n",
    "        [ 0.03817582,  0.03510211]]),\n",
    " 'da2': np.array([[ 0.39561478,  0.36376198],\n",
    "        [ 0.7674101 ,  0.70562233],\n",
    "        [ 0.0224596 ,  0.02065127],\n",
    "        [-0.18165561, -0.16702967]]),\n",
    " 'da3': np.array([[ 0.44888991,  0.41274769],\n",
    "        [ 0.31261975,  0.28744927],\n",
    "        [-0.27414557, -0.25207283]]),\n",
    " 'db1': 0.75937676204411464,\n",
    " 'db2': 0.86163759922811056,\n",
    " 'db3': -0.84161956022334572}\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    np.random.seed(3)\n",
    "    dW1 = np.random.randn(3,4)\n",
    "    db1 = np.random.randn(3,1)\n",
    "    dW2 = np.random.randn(1,3)\n",
    "    db2 = np.random.randn(1,1)\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return parameters, grads\n",
    "\n",
    "\n",
    "def L_model_forward_test_case_2hidden():\n",
    "    np.random.seed(6)\n",
    "    X = np.random.randn(5,4)\n",
    "    W1 = np.random.randn(4,5)\n",
    "    b1 = np.random.randn(4,1)\n",
    "    W2 = np.random.randn(3,4)\n",
    "    b2 = np.random.randn(3,1)\n",
    "    W3 = np.random.randn(1,3)\n",
    "    b3 = np.random.randn(1,1)\n",
    "  \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return X, parameters\n",
    "\n",
    "def print_grads(grads):\n",
    "    print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "    print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "    print (\"dA1 = \"+ str(grads[\"dA1\"]))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inilitize_parameters(n_X,n_h,n_y):\n",
    "    np.random.seed(1)\n",
    "    W1=np.random.randn(n_h,n_X)* 0.01\n",
    "    b1=np.zeros(shape=(n_h,1))\n",
    "    W2=np.random.randn(n_y,n_h)* 0.01\n",
    "    b2=np.zeros(shape=(n_y,1))\n",
    "    assert(W1.shape==(n_h,n_X))\n",
    "    assert(b1.shape==(n_h,1))\n",
    "    assert(W2.shape==(n_y,n_h))\n",
    "    assert(b2.shape==(n_y,1))\n",
    "    parameters={\"W1\":W1,\"b1\":b1,\"W2\":W2,\"b2\":b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=inilitize_parameters(3,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilize_params_deep(layers):\n",
    "    np.random.seed(3)\n",
    "    parameters={}\n",
    "    l=len(layers)\n",
    "    for i in range(1,l):\n",
    "        parameters[\"W\"+ str(i)]=np.random.randn(layers[i],layers[i-1])\n",
    "        parameters[\"b\"+str(i)]=np.zeros(shape=(layers[i],1))\n",
    "        assert(parameters[\"W\"+ str(i)].shape==(layers[i],layers[i-1]))\n",
    "        assert(parameters[\"b\"+str(i)].shape==(layers[i],1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 1.78862847],\n",
       "        [ 0.43650985],\n",
       "        [ 0.09649747],\n",
       "        [-1.8634927 ]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[-0.2773882 , -0.35475898, -0.08274148, -0.62700068],\n",
       "        [-0.04381817, -0.47721803, -1.31386475,  0.88462238],\n",
       "        [ 0.88131804,  1.70957306,  0.05003364, -0.40467741],\n",
       "        [-0.54535995, -1.54647732,  0.98236743, -1.10106763],\n",
       "        [-1.18504653, -0.2056499 ,  1.48614836,  0.23671627]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[-1.02378514, -0.7129932 ,  0.62524497, -0.16051336, -0.76883635],\n",
       "        [-0.23003072,  0.74505627,  1.97611078, -1.24412333, -0.62641691],\n",
       "        [-0.80376609, -2.41908317, -0.92379202, -1.02387576,  1.12397796],\n",
       "        [-0.13191423, -1.62328545,  0.64667545, -0.35627076, -1.74314104],\n",
       "        [-0.59664964, -0.58859438, -0.8738823 ,  0.02971382, -2.24825777],\n",
       "        [-0.26776186,  1.01318344,  0.85279784,  1.1081875 ,  1.11939066]]),\n",
       " 'b3': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W4': array([[ 1.48754313, -1.11830068,  0.84583341, -1.86088953, -0.6028851 ,\n",
       "         -1.91447204]]),\n",
       " 'b4': array([[0.]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initilize_params_deep([1,4,5,6,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fwd(A,W,b):\n",
    "    Z=np.dot(W,A)+b\n",
    "    (Z.shape==(W.shape[0],A.shape[1]))\n",
    "    cache=(A,W,b)\n",
    "    return Z,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,W,b=linear_activation_forward_test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,lin_cache=linear_fwd(A,W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_activation(A_prev,W,b,activation_fn):\n",
    "    if activation_fn==\"sigmoid\":\n",
    "        Z,linear_cache=linear_fwd(A_prev,W,b)\n",
    "        A,activation_cache=sigmoid(Z)\n",
    "    if activation_fn==\"relu\":\n",
    "        Z,linear_cache=linear_fwd(A_prev,W,b)\n",
    "        A,activation_cache=relu(Z)        \n",
    "    cache=(linear_cache,activation_cache)\n",
    "    return A,cache\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,W,b=linear_activation_forward_test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,cach=lin_activation(A,W,b,activation_fn=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_forward(X,parameters):\n",
    "    l=len(parameters)//2\n",
    "    total_cache=[]\n",
    "    A=X\n",
    "    for i in range(1,l):\n",
    "        A_prev=A\n",
    "        A,cache=lin_activation(A_prev,parameters[\"W{:d}\" .format(i)],parameters[\"b{:d}\".format(i)],activation_fn=\"relu\")\n",
    "        total_cache.append(cache)\n",
    "    Al,cache=lin_activation(A,parameters[\"W{:d}\".format(l)],parameters[\"b{:d}\".format(l)],activation_fn=\"sigmoid\")\n",
    "    total_cache.append(cache)\n",
    "    return Al,total_cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,parameters=L_model_forward_test_case_2hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_final,Tcache=l_forward(X,parameters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://github.com/HeroKillerEver/coursera-deep-learning/tree/master/Neural%20Networks%20and%20Deep%20Learning/Deep%20Neural%20Network%20Application-Image%20Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(AL,Y):\n",
    "    m=Y.shape[1]\n",
    "    cost=-1/m * np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape==())\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " Y,AL=compute_cost_test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41493159961539694"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_fn(AL,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_bkward(dZ,cache):\n",
    "    A_prev,W,b=cache\n",
    "    m=A_prev.shape[1]\n",
    "    dW=1/m * np.dot(dZ,A_prev.T)\n",
    "    db=1/m * np.sum(dZ,keepdims=True,axis=1)\n",
    "    dA_prev=np.dot(W.T,dZ)\n",
    "    assert(dA_prev.shape==A_prev.shape)\n",
    "    assert(dW.shape==W.shape)\n",
    "    assert(db.shape==b.shape)\n",
    "    return dA_prev,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.51822968, -0.19517421],\n",
       "        [-0.40506361,  0.15255393],\n",
       "        [ 2.37496825, -0.89445391]]),\n",
       " array([[-0.10076895,  1.40685096,  1.64992505]]),\n",
       " array([[0.50629448]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ,cache=linear_backward_test_case()\n",
    "linear_bkward(dZ,cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bach_activation(dA,cache,activation):\n",
    "    linear_cache,activation_cache=cache\n",
    "    if activation==\"relu\":\n",
    "        dZ=relu_backward(dA,activation_cache)\n",
    "        dA_prev,dW,db=linear_bkward(dZ,linear_cache)\n",
    "    elif activation==\"sigmoid\":\n",
    "        dZ=sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev,dW,db=linear_bkward(dZ,linear_cache)\n",
    "    return dA_prev,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dAL, linear_activation_cache =linear_activation_backward_test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.11017994,  0.01105339],\n",
       "        [ 0.09466817,  0.00949723],\n",
       "        [-0.05743092, -0.00576154]]),\n",
       " array([[ 0.10266786,  0.09778551, -0.01968084]]),\n",
       " array([[-0.05729622]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bach_activation(dAL, linear_activation_cache, activation = \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_layer_backward(AL,Y,cache):\n",
    "    grads={}\n",
    "    L=len(cache)\n",
    "    m=AL.shape[1]\n",
    "    Y=Y.reshape(AL.shape)\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    current_cache=cache[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = bach_activation(dAL, current_cache, 'sigmoid')\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache=cache[l]\n",
    "        temp_dA,temp_dW,temp_db=bach_activation(grads[\"dA\"+ str(l+1)],current_cache,\"relu\")\n",
    "        grads[\"dA\" + str(l)]=temp_dA\n",
    "        grads[\"dW\" + str(l+1)]=temp_dW\n",
    "        grads[\"db\" + str(l+1)]=temp_db\n",
    "        \n",
    "    return grads\n",
    "    #dA_prev_temp, dW_temp, db_temp = bach_activation(grads[\"dA\" + str(l + 1)], current_cache, 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AL, Y_assess, caches = L_model_backward_test_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-721b79076a8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml_layer_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "l_layer_backward(AL,y_train,cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,grads,learning_rate):\n",
    "    L=len(parameters)//2\n",
    "    for l  in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, grads = update_parameters_test_case()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.59562069, -0.09991781, -2.14584584,  1.82662008],\n",
       "        [-1.76569676, -0.80627147,  0.51115557, -1.18258802],\n",
       "        [-1.0535704 , -0.86128581,  0.68284052,  2.20374577]]),\n",
       " 'b1': array([[-0.04659241],\n",
       "        [-1.28888275],\n",
       "        [ 0.53405496]]),\n",
       " 'W2': array([[-0.55569196,  0.0354055 ,  1.32964895]]),\n",
       " 'b2': array([[-0.84610769]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_parameters(parameters,grads,0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layeres_nn(X,Y,dim,iterations=500,print_cost=False,learning_rate=0.0075):\n",
    "    costs=[]\n",
    "    parameters=initilize_params_deep(dim)\n",
    "    for i in range(0,iterations):\n",
    "        AL,caches=l_forward(X,parameters)\n",
    "        cost=cost_fn(AL,Y)\n",
    "        grads=l_layer_backward(AL,Y,caches)\n",
    "        parameters=update_parameters(parameters,grads,learning_rate)\n",
    "        if print_cost==True and i%100==0:\n",
    "            print(\"cost after every %d iteration is:%f\"%(i,cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after every 0 iteration is:36.871929\n",
      "cost after every 100 iteration is:0.342872\n",
      "cost after every 200 iteration is:0.276008\n",
      "cost after every 300 iteration is:0.247491\n",
      "cost after every 400 iteration is:0.234577\n",
      "cost after every 500 iteration is:0.226499\n",
      "cost after every 600 iteration is:0.220830\n",
      "cost after every 700 iteration is:0.216705\n",
      "cost after every 800 iteration is:0.214555\n",
      "cost after every 900 iteration is:0.213017\n",
      "cost after every 1000 iteration is:0.211635\n",
      "cost after every 1100 iteration is:0.210450\n",
      "cost after every 1200 iteration is:0.209274\n",
      "cost after every 1300 iteration is:0.208170\n",
      "cost after every 1400 iteration is:0.207329\n",
      "cost after every 1500 iteration is:0.206630\n",
      "cost after every 1600 iteration is:0.205996\n",
      "cost after every 1700 iteration is:0.205241\n",
      "cost after every 1800 iteration is:0.204570\n",
      "cost after every 1900 iteration is:0.203956\n",
      "cost after every 2000 iteration is:0.203402\n",
      "cost after every 2100 iteration is:0.202901\n",
      "cost after every 2200 iteration is:0.202502\n",
      "cost after every 2300 iteration is:0.202113\n",
      "cost after every 2400 iteration is:0.201721\n",
      "cost after every 2500 iteration is:0.201237\n",
      "cost after every 2600 iteration is:0.200728\n",
      "cost after every 2700 iteration is:0.200358\n",
      "cost after every 2800 iteration is:0.200034\n",
      "cost after every 2900 iteration is:0.199735\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters=L_layeres_nn(X_train1, y_train, [2,20,16,7,6,1],iterations=3000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.10106763, -1.18504653]],\n",
       "\n",
       "       [[-0.2056499 ,  1.48614836]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poppy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(28,28).reshape(28*28,-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=(np.random.randn(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reshape((m).size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Sharath\\Desktop\\stuff\\Data science\\datasets\\housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"income_cat\"]=pd.cut(data[\"median_income\"],bins=[0.,1.5,3.0,4.5,6.,np.inf],labels=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=StratifiedShuffleSplit(n_splits=1,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index,test_index in split.split(data,data[\"income_cat\"]):\n",
    "    housing_train=data.iloc[train_index]\n",
    "    housing_test=data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Sharath\\Desktop\\stuff\\MLUDEMY\\Part 3 - Classification\\Section 15 - K-Nearest Neighbors (K-NN)\\Python\\Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,:-1]=sc.fit_transform(data.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=X_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [2,25,7, 5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = l_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9249999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_train1,y_train,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9374999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_test.T,y_test.reshape(1,-1),parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def L_layeres_nn(X,Y,layers_dims,learning_rate=0.0075,num_iterations=1500,print_cost=False):\n",
    "    costs=[]\n",
    "    parameters=initilize_params_deep(layers_dims)\n",
    "    for i in range(0,num_iterations):\n",
    "        AL,caches=l_forward(X,parameters)\n",
    "        cost=cost_fn(AL,Y)\n",
    "        grads=l_layer_backward(AL,Y,caches)\n",
    "        parameters=update_parameters(parameters,grads,learning_rate)\n",
    "        if print_cost and i%100==0:\n",
    "            print(\"cost after every %d iteration is:%f\" %(i,cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 1.78862847,  0.43650985],\n",
       "        [ 0.09649747, -1.8634927 ],\n",
       "        [-0.2773882 , -0.35475898]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[-0.08274148, -0.62700068, -0.04381817],\n",
       "        [-0.47721803, -1.31386475,  0.88462238],\n",
       "        [ 0.88131804,  1.70957306,  0.05003364],\n",
       "        [-0.40467741, -0.54535995, -1.54647732],\n",
       "        [ 0.98236743, -1.10106763, -1.18504653],\n",
       "        [-0.2056499 ,  1.48614836,  0.23671627],\n",
       "        [-1.02378514, -0.7129932 ,  0.62524497],\n",
       "        [-0.16051336, -0.76883635, -0.23003072],\n",
       "        [ 0.74505627,  1.97611078, -1.24412333],\n",
       "        [-0.62641691, -0.80376609, -2.41908317]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[-9.23792022e-01, -1.02387576e+00,  1.12397796e+00,\n",
       "         -1.31914233e-01, -1.62328545e+00,  6.46675452e-01,\n",
       "         -3.56270759e-01, -1.74314104e+00, -5.96649642e-01,\n",
       "         -5.88594380e-01],\n",
       "        [-8.73882298e-01,  2.97138154e-02, -2.24825777e+00,\n",
       "         -2.67761865e-01,  1.01318344e+00,  8.52797841e-01,\n",
       "          1.10818750e+00,  1.11939066e+00,  1.48754313e+00,\n",
       "         -1.11830068e+00],\n",
       "        [ 8.45833407e-01, -1.86088953e+00, -6.02885104e-01,\n",
       "         -1.91447204e+00,  1.04814751e+00,  1.33373782e+00,\n",
       "         -1.97414679e-01,  1.77464503e+00, -6.74727510e-01,\n",
       "          1.50616865e-01],\n",
       "        [ 1.52945703e-01, -1.06419527e+00,  4.37946611e-01,\n",
       "          1.93897846e+00, -1.02493087e+00,  8.99338446e-01,\n",
       "         -1.54506852e-01,  1.76962730e+00,  4.83788348e-01,\n",
       "          6.76216400e-01],\n",
       "        [ 6.43163281e-01,  2.49086707e-01, -1.39576350e+00,\n",
       "          1.39166291e+00, -1.37066901e+00,  2.38563192e-01,\n",
       "          6.14077088e-01, -8.37912273e-01,  1.45063214e-01,\n",
       "          1.16788229e+00],\n",
       "        [-2.41044701e-02, -8.88657418e-01, -2.91573775e+00,\n",
       "         -9.71840503e-01, -5.91078738e-01, -5.16417368e-01,\n",
       "         -9.59996180e-01,  3.77295234e-01, -5.74708420e-01,\n",
       "         -1.09454334e-01],\n",
       "        [ 6.79071600e-01, -8.55437169e-01, -3.00206075e-01,\n",
       "          2.15814934e+00,  8.74285723e-01, -1.29353663e+00,\n",
       "         -7.97409382e-02,  5.64485518e-01,  1.23347104e+00,\n",
       "          1.48986395e-01],\n",
       "        [-5.30582144e-01, -7.30526644e-01,  6.45061985e-01,\n",
       "          3.13060374e-01, -5.16647925e-01, -1.89071666e-01,\n",
       "         -4.16198015e-01,  7.24657658e-01, -6.89960677e-01,\n",
       "          4.86414475e-01],\n",
       "        [ 8.51518950e-01,  4.86249326e-01, -8.34239851e-01,\n",
       "          1.34499246e+00, -6.78212679e-01,  4.26435074e-01,\n",
       "         -7.53334794e-01, -1.74411025e+00,  2.25750266e-01,\n",
       "          2.87035165e-01],\n",
       "        [-7.74409606e-02,  2.76068497e-01, -6.48410888e-01,\n",
       "         -7.37464837e-01, -1.68090099e-01,  1.90927681e+00,\n",
       "          8.14814541e-01, -5.19991754e-01,  5.58713205e-01,\n",
       "         -4.78364660e-01],\n",
       "        [-4.57260787e-01,  8.59284008e-01, -5.25264645e-01,\n",
       "         -1.67563463e+00, -9.06494701e-01,  8.84152062e-02,\n",
       "          1.28007821e-01,  1.24161652e+00, -7.16025798e-01,\n",
       "          7.31465736e-01],\n",
       "        [ 4.25966750e-01, -1.49013772e-01,  8.35843902e-01,\n",
       "          4.92118903e-01, -8.62308487e-01,  1.07168393e+00,\n",
       "         -1.22090192e+00,  5.96154331e-02,  2.44416199e-03,\n",
       "          4.24635721e-01],\n",
       "        [-7.25433480e-01, -3.49433856e-02, -1.40620027e-01,\n",
       "          9.97088367e-01, -7.95914693e-01,  7.27455292e-02,\n",
       "         -2.61240485e-01, -1.29804664e+00,  2.67611247e+00,\n",
       "         -7.12190272e-02],\n",
       "        [-1.48665807e+00,  1.40862696e+00, -1.07058550e+00,\n",
       "          3.70869972e-01,  8.62832095e-01, -6.48432023e-01,\n",
       "         -4.30890055e-01, -5.40270264e-01, -1.29361010e-01,\n",
       "         -1.62246117e+00],\n",
       "        [-1.23563662e+00, -1.40786442e-01,  1.03895212e+00,\n",
       "          6.31744177e-01,  1.72941743e+00,  6.94052272e-01,\n",
       "         -5.11128993e-01, -1.22843406e-01, -2.03039355e+00,\n",
       "         -9.60775110e-01],\n",
       "        [-1.02035928e+00,  2.70593425e-01,  6.47829797e-01,\n",
       "         -5.60373419e-01, -5.88501620e-01, -1.54655582e+00,\n",
       "         -1.27762058e-01,  2.48168027e-01,  4.45780959e-01,\n",
       "         -7.82709043e-01],\n",
       "        [ 1.98848968e+00,  1.19505834e+00, -9.52375987e-02,\n",
       "         -5.27187779e-01, -3.21584693e-01,  1.51130372e-01,\n",
       "         -1.86277156e-02,  4.83528787e-01,  7.68965158e-01,\n",
       "          1.36624284e+00],\n",
       "        [ 1.14726479e+00, -1.10229155e-01,  3.88250414e-01,\n",
       "         -3.87127181e-01, -5.87220312e-01,  1.91082685e+00,\n",
       "         -4.59846150e-01,  1.99073781e+00, -3.49035393e-01,\n",
       "          2.52825091e-01],\n",
       "        [ 1.08940955e+00,  2.39220218e-02,  3.93125281e-01,\n",
       "         -2.41384800e-01, -4.75524858e-01, -1.65777023e-01,\n",
       "         -6.49717421e-01,  1.63138295e+00, -1.67698603e-01,\n",
       "          1.72266920e+00],\n",
       "        [-2.68510868e+00,  1.84207947e-02,  5.61951672e-01,\n",
       "         -2.93821238e-01,  1.09465308e+00,  6.39692355e-01,\n",
       "         -2.74600120e-01,  4.35009258e-01,  2.81187838e+00,\n",
       "          2.51995127e-01]]),\n",
       " 'b3': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W4': array([[ 0.29950233, -0.43999131,  0.13349704, -1.28926119, -0.19829026,\n",
       "          2.45758763,  1.06721555,  0.64142066,  1.10392166,  1.88175499,\n",
       "          0.59358811,  2.07087853,  1.06979836,  0.16651951,  1.71947656,\n",
       "         -2.35921474, -0.57134896,  0.26578705, -0.91209091, -0.1560584 ],\n",
       "        [-0.6387909 , -0.65441521,  2.71192633,  0.62747389, -0.05394785,\n",
       "          1.31516722, -0.23733748,  0.88533968,  0.35081584,  1.6265736 ,\n",
       "         -1.41987131,  0.76572107,  0.12224975, -1.15738338,  1.06542018,\n",
       "         -0.87237566,  1.61923848,  0.51309301,  0.69548398,  0.08045739],\n",
       "        [ 0.90452849, -1.86565117,  0.07472779, -0.62825081,  0.28266031,\n",
       "         -0.04715691,  0.61657788, -0.83763145,  1.83915189,  2.3158586 ,\n",
       "         -0.20828342, -0.01497319,  0.28755765,  1.26408575,  1.89690096,\n",
       "         -1.20580279, -0.61510856, -1.06215612, -1.11278115, -1.63929625],\n",
       "        [ 0.36280349, -1.15903647,  1.50326195,  0.90831872, -1.02970953,\n",
       "         -1.03020862, -0.61238442,  1.3999655 , -0.84960736, -1.49354967,\n",
       "         -0.04942389,  0.37338994, -0.65725749,  1.61943081,  0.24045678,\n",
       "          0.45303779, -0.85553272, -0.03972984, -0.15651881, -2.27224411],\n",
       "        [ 0.28765723, -1.79480704, -0.02878565, -1.47394283,  2.01965064,\n",
       "          0.32626227,  0.86135761,  0.91900813, -1.3244887 , -2.28179231,\n",
       "         -0.32957815,  0.89714975,  0.09103451,  0.78543225,  0.93663257,\n",
       "         -1.4923971 ,  0.28768372,  1.96647463, -0.5705323 , -2.02907213],\n",
       "        [-0.23190455, -0.46466872,  0.41838102, -0.89240633,  0.09071677,\n",
       "         -2.21741761,  0.85396337,  1.58686654,  1.29787761, -1.51521566,\n",
       "          0.31919618, -2.9839702 ,  0.28318592, -0.06436017, -0.99579424,\n",
       "          0.34379452,  0.13801466,  0.93950285,  0.12730852,  0.23502701],\n",
       "        [-1.94507226, -1.15972295, -0.47589939,  0.29684453, -0.00629878,\n",
       "          1.50089036, -0.87015919, -0.23963207,  0.25508069, -0.23149741,\n",
       "          0.4955804 , -0.57056282,  1.42034231, -0.31959014,  1.11594518,\n",
       "         -0.03030337,  1.49152235, -1.39811601,  0.51679755, -0.43257638],\n",
       "        [ 0.23140076,  1.19280517, -1.1390968 , -1.32202973, -0.99836688,\n",
       "          0.25438757, -1.88683693,  0.09659373, -1.28622933, -1.14372183,\n",
       "         -0.36917775,  0.38059758, -0.6264145 , -0.49204389, -0.04184423,\n",
       "         -0.27273554, -2.67652137, -0.43010061,  0.08496406,  1.09777949],\n",
       "        [ 2.04633278,  0.66698785,  0.07909219, -0.96476347,  0.08905337,\n",
       "          0.7788969 ,  1.26464491, -0.88051133,  0.2364056 ,  0.81560447,\n",
       "          1.86081167,  0.25559049, -0.54150372, -0.68959966, -0.35744073,\n",
       "         -0.6519202 ,  0.82653585,  1.06930572,  0.72485682,  1.19218624],\n",
       "        [-0.45376854,  0.38033506, -0.38466318,  0.04365869,  1.22498574,\n",
       "         -0.02973531, -1.8648058 , -0.25281599, -0.7128498 , -1.50891712,\n",
       "         -0.79036569,  0.9606248 ,  1.68091065, -0.48900604,  1.00253584,\n",
       "          1.1782221 , -1.15979227, -0.0393627 , -0.04446017,  0.17238568],\n",
       "        [-1.59375081, -0.34914224,  1.05782121,  1.2622032 ,  1.83136208,\n",
       "         -0.33750905,  1.86950756,  0.66590511, -1.35920117,  0.76160928,\n",
       "         -0.35228003,  0.51907626, -0.10252394,  1.20823864,  0.25656016,\n",
       "         -0.28250502,  0.96496577,  0.25622178, -0.4129564 ,  1.27727436],\n",
       "        [-0.40834524, -0.63713486, -0.53957461, -1.46547209, -0.55320717,\n",
       "          1.86087769, -0.90828394,  0.0084189 , -1.10818335, -0.61135315,\n",
       "          1.51869216,  0.89635574, -0.61025035,  0.00622012, -0.82600396,\n",
       "         -0.78420535, -0.9148222 , -0.89713978,  0.32594927,  0.59679317],\n",
       "        [ 0.48824249, -0.16943686, -1.3580452 , -0.06711047, -0.92429374,\n",
       "          0.88130113,  0.55644294,  0.74689153, -0.34836832, -1.81101917,\n",
       "          0.95789639,  1.22632133, -1.48331661,  0.13791604,  1.19325258,\n",
       "         -1.07572355,  1.76768278, -0.34903246, -1.07539011,  1.37165804],\n",
       "        [ 0.29453214, -0.65313816,  0.87978795, -1.95576713,  1.81530638,\n",
       "         -0.81625006,  0.28598427, -0.39861617,  0.43623211,  0.88792572,\n",
       "         -0.8238861 ,  0.78636292, -0.29403325, -0.68785951, -0.22404361,\n",
       "         -1.00460861, -0.79566757,  0.94913384, -0.15082304,  1.1415331 ],\n",
       "        [ 0.43175699, -1.0259683 , -1.89787143, -0.68724182,  0.26412649,\n",
       "          0.00881292, -0.83009562,  1.0128123 , -1.7457235 , -1.25864659,\n",
       "          0.1272951 ,  2.19376315,  0.41393413, -1.00523966,  0.59265714,\n",
       "          0.68339657,  0.93785693, -0.40986453, -0.79972644,  0.11821728],\n",
       "        [ 0.41527488,  1.59823525,  2.08964887, -0.73306993, -0.52297163,\n",
       "         -0.06357308, -0.24977211,  0.48579018,  0.48573721,  0.25789698,\n",
       "          1.34407129, -0.15851092, -1.05080794, -1.56060123, -1.02813987,\n",
       "         -1.04425792, -1.88342383,  0.66318777,  0.18526784, -0.42279273],\n",
       "        [-0.88988898, -1.58094538, -0.9197196 ,  1.84790906, -2.21079164,\n",
       "          0.14181052,  0.74363697,  0.13613223, -0.31680492,  0.76807394,\n",
       "         -1.10332826,  0.555545  ,  1.43069737, -1.04137439, -0.81983341,\n",
       "          0.13594038,  0.9895728 ,  1.3391483 ,  0.68062695, -0.66950277],\n",
       "        [-1.11441271,  0.24297858,  0.39825763, -1.10055231,  0.05979049,\n",
       "          0.33223747,  1.04506399, -0.9905627 ,  0.55696453, -1.1692758 ,\n",
       "         -0.42658598, -0.07827675,  1.51791626,  3.31430424,  0.25354568,\n",
       "          0.4952915 ,  1.00754161, -1.36165622,  0.7656634 , -1.24173986],\n",
       "        [ 1.62911197,  1.44349176,  0.50153968, -0.80669851,  1.66802527,\n",
       "          0.25968837,  0.11024354,  0.57954335, -1.71234657,  0.42849942,\n",
       "          0.99610815,  0.33900098,  0.14525875, -0.95365812,  0.64355483,\n",
       "          0.20046895,  0.00906379, -0.56320492,  0.85617111,  1.24718437],\n",
       "        [ 0.38814617,  0.89674907,  1.3260233 ,  1.58816115,  0.22565015,\n",
       "         -0.21332802, -0.41494587,  0.01374701,  0.55196641,  0.93818194,\n",
       "         -0.42674202,  0.14985756, -0.99658002,  1.26396401, -0.39146105,\n",
       "          0.35792113, -0.71937006, -0.29827604, -0.6859961 ,  1.70496656],\n",
       "        [ 0.35936374, -0.16644467, -0.94764232, -0.61029971,  0.56870506,\n",
       "          1.66592502, -1.43088883, -0.91704656, -0.17578816, -0.62826735,\n",
       "         -1.65918207,  0.01930975,  0.75104255, -1.57711136,  0.21095978,\n",
       "          0.96467291,  0.98032733, -0.41987069,  2.30474905,  0.5551134 ],\n",
       "        [-0.81106622,  0.98429894, -1.12258797,  0.89526945, -1.26205434,\n",
       "          0.79054257, -0.58356177,  1.13228806,  0.74067741,  0.44720792,\n",
       "          0.05863243,  1.08701626, -1.80334191,  0.43255434,  0.4134327 ,\n",
       "          0.56214989,  0.82622882,  3.70245824,  0.11678267,  0.80449953],\n",
       "        [ 0.1523685 ,  1.57266807, -2.02081048,  1.69794753, -0.68380642,\n",
       "         -2.26224129, -1.07818558, -0.17451934,  0.19424525, -0.04589136,\n",
       "          0.81681772, -0.03517699, -0.0631976 , -2.14351553,  0.48734407,\n",
       "          1.0102417 , -0.42067283, -1.8770843 , -1.33650549,  1.67356164],\n",
       "        [-0.60620725, -0.66458388, -0.81945109,  0.68088412, -0.58784355,\n",
       "         -0.86903192, -1.50636278, -0.10779898,  1.00094767, -0.14793288,\n",
       "          0.88221968,  0.17542639,  0.14783687,  0.17897291,  0.03444142,\n",
       "          1.02620502,  0.4878529 , -0.57811068,  0.12862005, -0.07596463],\n",
       "        [ 0.48493198,  0.18031665,  0.41457794, -1.47732184,  0.37959116,\n",
       "          1.31361206, -1.35019394,  1.60093254,  0.29707272, -0.2077485 ,\n",
       "         -1.80448815,  1.08759702, -0.96954954, -0.51119077,  0.54590427,\n",
       "         -1.02557987, -0.9868334 , -1.15128032, -0.11136018,  0.58853642],\n",
       "        [ 0.40300606,  0.40740281, -0.34418024,  0.14046942, -0.69004075,\n",
       "          1.99767531,  0.19472715, -1.95498537, -1.0693078 ,  1.60130281,\n",
       "         -1.36648729, -0.43769479,  0.40362572, -1.09662368,  1.0666047 ,\n",
       "          1.67908348, -0.82473917,  1.12929566, -0.89122301, -0.99794991],\n",
       "        [ 0.24568509,  0.23793134, -0.5960354 ,  0.84202424, -1.46918165,\n",
       "         -0.85566594, -1.07786939,  0.75836367,  0.8039022 ,  0.66694045,\n",
       "         -1.29560047,  0.13276813,  0.45765351, -1.61697998, -0.8216931 ,\n",
       "          0.64586234,  0.70365416,  0.2552348 ,  0.54207567,  0.32409606],\n",
       "        [ 0.14991872, -0.10925686, -0.87143223, -0.24554832, -0.40291494,\n",
       "          2.31777471,  0.26024073, -0.01069513, -0.2319775 , -0.11520507,\n",
       "         -0.27226691,  0.54470501, -0.02944483,  0.8110797 , -0.69517609,\n",
       "          0.35023459,  0.8771562 , -1.15425899,  0.16777   ,  0.24706745],\n",
       "        [-0.33474727, -0.48716098, -1.85491011,  1.14882126, -0.93292379,\n",
       "         -1.24037054,  0.65791347, -1.83227469,  0.96327113,  0.43421913,\n",
       "          0.59808962, -0.16400084, -1.21734657, -1.88876298,  1.45681202,\n",
       "         -0.47194095, -0.51668115,  1.58216276, -0.63140247, -0.23795968],\n",
       "        [-0.23699844, -0.13745974, -1.03944187, -0.56021371,  1.28548905,\n",
       "          0.76109313, -2.97712531, -1.95853164,  0.33363677, -0.11295429,\n",
       "         -0.37452644,  1.0427393 , -1.78425933,  1.19959205,  0.13159092,\n",
       "          0.54840607,  0.2533699 ,  0.84614069, -0.25033179, -0.54225803],\n",
       "        [ 0.78157133,  0.17510279, -1.25428849,  1.34961417,  1.2107645 ,\n",
       "          1.44143788,  0.07969699,  0.35053274, -0.38154238, -0.97282931,\n",
       "          0.06547206,  0.1765085 , -0.66276142,  1.82969481, -1.61591476,\n",
       "         -0.8153447 , -0.67137121,  1.2912054 , -0.25659048, -0.32493828],\n",
       "        [-0.88549128, -0.76449531, -1.30461987,  1.01553721,  0.60889056,\n",
       "          0.99003399, -0.66235984,  2.51191688, -0.9813121 , -2.05381367,\n",
       "         -0.29210985,  0.13711937,  0.75634064, -1.01743069,  0.59085522,\n",
       "          1.70785239, -0.85192477, -0.7401664 , -1.70286038,  0.24094099],\n",
       "        [ 0.85741377,  0.76694066,  0.83362317,  1.41614694,  0.12744248,\n",
       "          0.95277198, -0.95161721, -0.79090653,  0.24086618, -0.8180217 ,\n",
       "          0.57170321,  1.3750514 ,  0.40353627, -0.73743155, -0.74847586,\n",
       "          1.36536651, -0.79813582,  0.08931731, -0.25889486,  0.05302142],\n",
       "        [ 1.09636939, -0.53879311, -1.41039285,  1.45173615,  0.22301415,\n",
       "          0.72572913, -0.01937808,  0.77762307,  1.26473756,  1.36632632,\n",
       "         -0.27345407, -0.35215232,  0.39486824,  0.20717154,  0.56579628,\n",
       "         -0.71093871, -2.32469883,  0.45001987,  0.78124562,  0.6430152 ],\n",
       "        [ 1.65944291,  0.85222884, -0.38833337,  0.98542591, -0.08493475,\n",
       "          1.255285  ,  0.23798779,  0.45351064,  0.22772375,  0.05450504,\n",
       "         -1.4965727 ,  0.05773997, -2.27254827,  0.497803  ,  0.99191892,\n",
       "          2.05110328,  0.3740764 , -0.71649648, -1.58957659,  1.94777016],\n",
       "        [-1.42627027,  0.8955234 , -2.3062695 , -0.05148937,  0.68322351,\n",
       "          0.3252358 , -0.04154044, -0.8247089 , -0.90666617,  1.00862857,\n",
       "          0.43572994, -0.16058843,  0.20682684, -0.92670237,  1.02229087,\n",
       "          1.26097437, -0.77985076,  0.10202089,  1.0482473 , -0.64182853],\n",
       "        [ 2.03457678,  1.51062896, -0.27887595,  0.97877212,  1.66219648,\n",
       "         -1.24409046,  0.61922421, -0.14435019, -0.21653645,  0.71030659,\n",
       "         -0.47707723, -1.39975241, -1.42216236, -0.01973534,  0.62890132,\n",
       "         -0.02387657, -0.15259542, -0.03079642,  1.28931296,  0.53045333],\n",
       "        [-0.74591105, -0.28878466,  1.20468905, -0.58030216, -0.39473588,\n",
       "         -0.02506427, -1.06491087,  0.90236805, -2.18947387,  1.45137211,\n",
       "         -0.43515836, -1.25658162,  0.28226348, -1.7112236 ,  0.53735034,\n",
       "          0.773624  , -0.57591035, -0.38889544,  0.94874479, -0.67074472],\n",
       "        [ 0.02250233,  0.34761652,  1.55995984, -0.50307522,  0.03468126,\n",
       "          1.13200741, -2.55672653, -0.26895731, -1.90962033, -1.84007405,\n",
       "          1.95697012,  0.21127981,  1.483487  , -0.24141007,  0.54045273,\n",
       "         -0.43166677, -0.54695145, -0.07463858,  0.12833227,  1.53326944],\n",
       "        [-0.19682801,  0.37983923, -0.25692337,  0.1448681 , -1.31117671,\n",
       "          1.09142226, -0.52087614,  0.04153348, -0.2141505 ,  0.98464788,\n",
       "          0.52166434,  0.0129932 ,  0.17500062,  0.34343944,  0.75654462,\n",
       "          0.50695961,  1.28520704,  1.61842451,  0.61441535, -1.32260898]]),\n",
       " 'b4': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initilize_params_deep([2,3,10,20,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
